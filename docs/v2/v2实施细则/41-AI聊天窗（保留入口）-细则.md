# 41 - AI 聊天窗（保留入口，Text/SSE/WS）- v2 实施细则

> 对应 `docs/v2/v2实现步骤总览.md` Step 41  
> 状态：Draft（可开工）  
> 版本：v2.0  
> 创建日期：2026-01-19  
> 最后更新：2026-01-19

---

## 模块名称

AI 聊天窗（Chat Window）：作为 v2 的稳定入口，承接用户自然语言输入、追问解释与兜底交互，并与 Router Agent（Step 37）/Insight Cards（Step 39）/Intent Execution（Step 40）通过同一套契约联动

---

## 目标 / 非目标

### 目标

- 保留“聊天窗”作为 **永远存在的稳定入口**（RD 中 v1→v2 的关键复用点）：
  - 用户表达需求、追问 why、解释口径、兜底交互
  - 与导演式洞察卡并存：洞察卡是主线叙事，聊天窗是稳定入口与兜底
- 支持 **流式输出**（streaming）与 **双通道**：
  - `channel=text`：优先 SSE（Server-Sent Events）流式输出
  - `channel=voice`：WebSocket（后续可扩展 VAD/打断/原生音频；不在本细则落地）
- 严格对齐三条红线：
  - **权限旁路**：聊天窗的文本/CTA/Intent 全部 Mode-aware；执行仍必须过 UI Orchestration 门控（Step 40）
  - **predicted 混批次**：聊天上下文与工具调用必须顶层锁定 `prediction_run_id`
  - **交互风暴**：聊天输入不会因 hover/刷选高频触发 DP 重请求；只在 submit/CTA 执行后触发

### 非目标

- 不在本细则实现 Router Agent/Expertise Agents（Step 37/38）。
- 不在本细则实现 Insight Cards（Step 39）。
- 不在本细则实现语音端到端（VAD/STT/TTS、barge-in）与音频协议细节（仅保留 WS 接口与消息形态）。
- 不在本细则实现 Google Contextual View AI kit 的具体 UI 细节（只定义“集成位置与降级策略”）。

---

## 关联的数据产品（Data Product）

聊天窗的解释/取证只能引用数据产品（避免口径漂移）：

- L0 Dashboard（Step 11）
- L1 Region Intelligence（Step 13）
- L2 Evidence（Step 33，仅在用户显式追问或 CTA 下钻触发）
- Map Overlays（Step 12，可选：用于解释 legend/阈值/图层可用性）

---

## 输入维度（最小集合）

### 1) Chat 请求输入（前端 → 后端 Agent）

- `session_id`
- `channel`：`text` | `voice`
- `user_input`
- `client_view_state`（必须传，避免 AI 猜测 UI 状态；字段命名与 Step 37 一致）：
  - `region_scope/region_code`
  - `time_range`
  - `data_type`
  - `weather_type`
  - `product_id`（可选）
  - `access_mode`
  - predicted：`prediction_run_id`（或 active_run 等价注入后回填）
  - `capability_flags`（Details/Compare/Export…）
- `trace_id/correlation_id`

### 2) Chat UI 执行上下文（本地）

- `is_animating`（动画 gate，来自 UI Orchestration）
- `network_state`（online/offline，用于降级提示）

---

## 输出形态

### 1) 统一响应 Envelope（最终帧）

> 最终帧必须可被持久化与回放；字段命名以 Shared Contract 为准（Step 01）。

- `assistant_message`（最终文本；语音模式为 1–2 句摘要）
- `insight_cards[]`（可选；与 Step 39 形态一致）
- `ui_intents[]`（结构化意图；与 Step 40 schema 对齐）
- `meta`：
  - `access_mode`
  - `prediction_run_id`（predicted）
  - `blocked_intents[]`（若 intent 被门控）
  - `latency_ms`（总耗时摘要）

### 2) 流式输出（SSE/WS）

#### SSE（channel=text）

- `event: message_delta`：逐段输出 `assistant_message`（增量文本）
- `event: final`：输出完整 Envelope（JSON）
- `event: error`：输出错误码与可恢复提示（不改变页面状态）

> SSE 响应建议强制 `Cache-Control: no-store`（Next.js SSE 示例明确）以避免代理缓存。

#### WS（channel=voice）

- `type=message_delta`：逐段输出（文本或音频占位；v2 先文本）
- `type=final`：完整 Envelope（JSON）
- `type=error`：错误码 + 可恢复提示

---

## Mode 规则（必须写）

### Demo/Public

- 文本：
  - 禁止输出敏感口径（精确金额、可识别保单/理赔 id、内部主键）
  - 允许：区间化 KPI、阈值/次数、趋势性描述、口径说明
- 动作（CTA/intent）：
  - 默认阻断：导出、全量明细、Admin-only 动作
  - `open_details` 若允许，必须是“摘要化 details”（由后端 L2 裁剪兜底）；否则降级为 `seek_timeline`/`open_panel(overview|timeline)`
- UX：
  - 对被阻断的需求：必须返回“为什么不可用 + 可替代路径”（避免沉默拒绝）

### Partner/Admin

- 允许更深解释与更强 CTA，但仍需：
  - intent 执行前后均可审计（见可观测/审计章节）
  - 任何明细仍以 BE 裁剪为准（前端不得假设自己能控制权限）

硬规则：

- **AI 只能提出 intent，最终执行必须走 UI Orchestration 门控**（Step 40）。

---

## predicted 规则（必须写）

- predicted 场景下聊天必须 **顶层锁定** `prediction_run_id`：
  - chat 请求体里携带当前页面锁定的 run_id
  - 工具调用（dp_*）必须使用同一 run_id（禁止“Agent 自行取最新 active_run”并隐式切换）
- 若用户在聊天中提出“切换到 predicted / 切换批次”的意图：
  - 只能产生结构化 intent（例如 `set_filters(data_type="predicted")` / `switch_prediction_run(run_id)`）
  - intent 仍需经过 Step 40 的门控与确认路径（避免误切导致解释断裂）
- 禁止混用证据：
  - L0/L1/L2/Overlays 引用必须同一 `prediction_run_id`
  - predicted 下不得引用“历史 claims 事实”作为预测证据（如需对比，必须显式说明来源与批次）

---

## 性能与可靠性

### 交互边界（强制）

- **仅 `chat_submit` 触发一次 Agent 调用**；输入框的 onChange 不触发网络请求。
- 任何 hover/刷选/滚动等高频交互，**不得**触发聊天窗自动重问或自动刷新。
- L2 Evidence 默认按需：仅在用户显式追问 why/details 或 CTA（open_details）触发。

### 流式协议建议（对齐官方用法）

- Next.js App Router 可用 Route Handler + `ReadableStream` 返回流式 Response（官方示例）；
- FastAPI 可用 `StreamingResponse(async_generator, media_type="text/event-stream")` 产出 SSE（官方示例）。

> 工程上推荐：Next.js 作为 BFF 统一对外 SSE（路由与鉴权），后端 FastAPI 专注 Agent 逻辑；但两端任一处实现 SSE 都可，只要契约与可观测字段一致。

### 失败与降级（必须）

- 网络/服务不可用：
  - UI 保持可用（不破坏当前 View State）
  - 返回可恢复提示（重试/手动操作 Top Bar/Ranking）
- 流式中断：
  - 允许展示“部分输出 + 中断提示”
  - 不执行任何未完成的 intent（只在 `final` 帧内携带 intents，并由 Orchestration 执行）

---

## 可观测性

必须形成闭环（与 Step 37/40 的事件链一致）：

- `chat_submit`
- `chat_stream_open` / `chat_stream_close`（含原因：normal/error/client_disconnect）
- `ai_tool_call`（Router/Expertise）
- `dp_*_query` / `dp_*_response`
- `ai_intent_proposed` → `ai_intent_validated` → `ai_intent_blocked_by_mode|ai_intent_executed`
- `ui_render_done`

必带字段（至少）：

- `trace_id/correlation_id`
- `session_id`
- `access_mode`
- `region_code/time_range/data_type/weather_type/product_id`
- predicted：`prediction_run_id`
- `channel`
- `latency_ms`（总耗时与关键阶段耗时）

---

## 复用声明（必须写清楚）

### Reuse Digest（必填引用）

- `docs/v2/v2复用逻辑摘录/RD-AI聊天窗与洞察联动.md`
- `docs/v2/v2复用逻辑摘录/RD-共享类型与接口契约.md`
- `docs/v2/v2复用逻辑摘录/RD-性能优化.md`
- `docs/v2/v2复用逻辑摘录/RD-分层职责与协作边界.md`

### 来自 v1 的可复用资产（R1）

- 复用“聊天窗可折叠/可最小化 + 双向状态同步 + token 与参数提取双产出”的思想；
- 但 v2 必须：
  - 把“参数提取结果”变为 **结构化 intents**，并走 Orchestration 门控（禁止聊天窗直接 setState 触发 L2 重请求）
  - 把“证据”绑定到 Data Products 与 `prediction_run_id`（禁止口径漂移/混批次）

### 不复用内容（R3）

- 不复用“聊天窗直接改写全局状态并立即触发明细重请求”的路径（会造成风暴与越权旁路）。

---

## 验收用例（可勾选）

### 功能（必须）

- [ ] 用户在聊天窗输入自然语言后，系统能生成可读解释，并产出结构化 intents（至少含 `set_filters/open_panel/seek_timeline` 之一）。
- [ ] intents 只在 `final` 帧出现，并通过 UI Orchestration 统一执行（可回放/可门控）。

### Mode（必须）

- [ ] Demo/Public 下不会输出敏感口径；越权 intent 会被阻断并给替代路径（blocked_intents 可观测）。

### predicted（必须）

- [ ] predicted 下对话链路不会混批次：dp 请求与解释均携带同一 `prediction_run_id`。

### 性能（必须）

- [ ] chat_submit 不会触发请求风暴；L2 仅在显式追问/CTA 下钻触发。
- [ ] SSE/WS 中断不导致 UI 状态撕裂（不执行半截 intents）。

---

## 两个“最常见失败模式”（必须写进每个模块）

### 失败模式 A：前端隐藏当权限

症状：Demo/Public 仍能通过聊天触发“明细/导出”或在回复中泄露敏感口径。  
硬规则：Agent 输出与 intents 都必须 Mode-aware；Orchestration 门控 + 后端裁剪兜底；blocked 可观测。

### 失败模式 B：predicted 混批次

症状：聊天解释引用了不同 prediction_run 的证据（看似合理但不可审计）。  
硬规则：顶层锁定 `prediction_run_id`；dp 请求/缓存 key 必含 run_id；最终 Envelope meta 回填 run_id。

---

## 风险与回滚策略

### 风险

- 流式协议实现不一致（SSE/WS）导致前端难以统一处理与回放（P1）。
- L2 被滥用（过度下钻）导致成本/延迟抖动（P0/P1）。

### 回滚策略

- 先回滚为“非流式一次性响应 + 只输出低风险 intents”（open_panel/seek_timeline），禁用 open_details。
- 若出现越权：收紧 Mode gate（blocklist + capability 默认关闭）并强化后端裁剪；清理相关缓存并审计。

